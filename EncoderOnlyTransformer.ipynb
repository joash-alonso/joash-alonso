{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joash-alonso/joash-alonso/blob/main/EncoderOnlyTransformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAZ6bDwqlabz",
        "outputId": "c0a6db2d-3ffc-4630-d874-9459dde1a0f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/573.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/573.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m573.5/573.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m924.6/924.6 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydantic 2.2.1 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.6.1 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q keras-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCVt-y8MlwgT",
        "outputId": "c19ccbef-6834-45b7-8150-71e7920c76d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import keras_nlp\n",
        "import tensorflow as tf\n",
        "import keras_core as keras\n",
        "from typing import Tuple, Dict\n",
        "\n",
        "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
        "physical_devices"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SST-2**: a text classification dataset and our \"end goal\". This dataset is often used to benchmark language models.\n",
        "\n",
        "**WikiText-103**: A medium sized collection of featured articles from English Wikipedia, which we will use for pretraining."
      ],
      "metadata": {
        "id": "w0t7Keo6Rqmr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhuE9Q7Fl4xT",
        "outputId": "508f3cc1-0d61-4598-82b7-ea225cdaca75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-raw-v1.zip\n",
            "\u001b[1m191984949/191984949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "Downloading data from https://dl.fbaipublicfiles.com/glue/data/SST-2.zip\n",
            "\u001b[1m7439277/7439277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-nlp/examples/bert/bert_vocab_uncased.txt\n",
            "\u001b[1m231508/231508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step       \n"
          ]
        }
      ],
      "source": [
        "# Download pretraining data.\n",
        "keras.utils.get_file(\n",
        "    origin=\"https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-raw-v1.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "wiki_dir = os.path.expanduser(\"~/.keras/datasets/wikitext-103-raw/\")\n",
        "\n",
        "# Download finetuning data.\n",
        "keras.utils.get_file(\n",
        "    origin=\"https://dl.fbaipublicfiles.com/glue/data/SST-2.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "sst_dir = os.path.expanduser(\"~/.keras/datasets/SST-2/\")\n",
        "\n",
        "# Download vocabulary data.\n",
        "vocab_file = keras.utils.get_file(\n",
        "    origin=\"https://storage.googleapis.com/tensorflow/keras-nlp/examples/bert/bert_vocab_uncased.txt\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6LvBstOmJlS"
      },
      "outputs": [],
      "source": [
        "# Preprocessing params.\n",
        "PRETRAINING_BATCH_SIZE = 128\n",
        "FINETUNING_BATCH_SIZE = 32\n",
        "SEQ_LENGTH = 128\n",
        "MASK_RATE = 0.25\n",
        "PREDICTIONS_PER_SEQ = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4qSO8IcmR_w",
        "outputId": "8a2cad4c-d394-4eb5-9f0f-578f4a49a906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
            "array([b'hide new secretions from the parental units ',\n",
            "       b'contains no wit , only labored gags ',\n",
            "       b'that loves its characters and communicates something rather beautiful about human nature ',\n",
            "       b'remains utterly satisfied to remain the same throughout '],\n",
            "      dtype=object)>, <tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 1, 0], dtype=int32)>)\n"
          ]
        }
      ],
      "source": [
        "# Load SST-2.\n",
        "sst_train_ds = tf.data.experimental.CsvDataset(\n",
        "    sst_dir + \"train.tsv\", [tf.string, tf.int32], header=True, field_delim=\"\\t\"\n",
        ").batch(FINETUNING_BATCH_SIZE)\n",
        "\n",
        "sst_val_ds = tf.data.experimental.CsvDataset(\n",
        "    sst_dir + \"dev.tsv\", [tf.string, tf.int32], header=True, field_delim=\"\\t\"\n",
        ").batch(FINETUNING_BATCH_SIZE)\n",
        "\n",
        "# Load wikitext-103 and filter out short lines.\n",
        "wiki_train_ds = (\n",
        "    tf.data.TextLineDataset(wiki_dir + \"wiki.train.raw\")\n",
        "    .filter(lambda x: tf.strings.length(x) > 100)\n",
        "    .batch(PRETRAINING_BATCH_SIZE)\n",
        ")\n",
        "\n",
        "wiki_val_ds = (\n",
        "    tf.data.TextLineDataset(wiki_dir + \"wiki.valid.raw\")\n",
        "    .filter(lambda x: tf.strings.length(x) > 100)\n",
        "    .batch(PRETRAINING_BATCH_SIZE)\n",
        ")\n",
        "\n",
        "# Take a peak at the sst-2 dataset.\n",
        "print(sst_train_ds.unbatch().batch(4).take(1).get_single_element())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbJk6x4emeWE",
        "outputId": "8e2008d2-04e6-4842-84f8-4fd658c1aa57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "   2105/Unknown \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.6435 - loss: 0.6466"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2105/2105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.6435 - loss: 0.6466 - val_accuracy: 0.7533 - val_loss: 0.5392\n",
            "Epoch 2/5\n",
            "\u001b[1m2105/2105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.7506 - loss: 0.5398 - val_accuracy: 0.7790 - val_loss: 0.4893\n",
            "Epoch 3/5\n",
            "\u001b[1m2105/2105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7824 - loss: 0.4876 - val_accuracy: 0.7969 - val_loss: 0.4673\n",
            "Epoch 4/5\n",
            "\u001b[1m2105/2105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7987 - loss: 0.4547 - val_accuracy: 0.8002 - val_loss: 0.4571\n",
            "Epoch 5/5\n",
            "\u001b[1m2105/2105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8093 - loss: 0.4317 - val_accuracy: 0.8002 - val_loss: 0.4532\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_core.src.callbacks.history.History at 0x7fdc84370ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Create an appropriate baseline model to compare our model against"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y64MNKFdoty_"
      },
      "source": [
        " # Masked Language Modelling\n",
        "\n",
        " We will be doing Masked Language Modelling for training as our dataset has no labels. Another way to train is by using Next Sentence Prediction (NSP) if we had labels. We will be focusing on MLM.\n",
        "\n",
        " **Definition**: *Masked language modeling predicts a masked token in a sequence, and the model can attend to tokens bidirectionally. This means the model has full access to the tokens on the left and right. Masked language modeling is great for tasks that require a good contextual understanding of an entire sequence. BERT is an example of a masked language model.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "d51YfQ6EmsnT",
        "outputId": "ac76b65f-5b5f-43cd-e686-ba2632d2a986"
      },
      "outputs": [
        {
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-dbaa4b2e7b0e>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# We use prefetch() to pre-compute preprocessed batches on the fly on the CPU.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m pretrain_ds = wiki_train_ds.map(\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mpreprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m ).prefetch(tf.data.AUTOTUNE)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2276\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2277\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmap_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2278\u001b[0;31m     return map_op._map_v2(\n\u001b[0m\u001b[1;32m   2279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2280\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     38\u001b[0m         input_dataset, map_func, preserve_cardinality=True, name=name)\n\u001b[1;32m     39\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     return _ParallelMapDataset(\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    161\u001b[0m         num_parallel_calls, dtype=dtypes.int64, name=\"num_parallel_calls\")\n\u001b[1;32m    162\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     variant_tensor = gen_dataset_ops.parallel_map_dataset_v2(\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mparallel_map_dataset_v2\u001b[0;34m(input_dataset, other_arguments, num_parallel_calls, f, output_types, output_shapes, use_inter_op_parallelism, deterministic, preserve_cardinality, metadata, name)\u001b[0m\n\u001b[1;32m   5802\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5803\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5804\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5805\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5806\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6654\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6656\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Length for attr 'output_shapes' of 0 must be at least minimum 1\n\t; NodeDef: {{node ParallelMapDatasetV2}}; Op<name=ParallelMapDatasetV2; signature=input_dataset:variant, other_arguments:, num_parallel_calls:int64 -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=deterministic:string,default=\"default\"; attr=preserve_cardinality:bool,default=false; attr=metadata:string,default=\"\"> [Op:ParallelMapDatasetV2] name: "
          ]
        }
      ],
      "source": [
        "# What is word piece tokenizer doing?\n",
        "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary=vocab_file,\n",
        "    sequence_length=SEQ_LENGTH,\n",
        "    lowercase=True,\n",
        "    strip_accents=True,\n",
        ")\n",
        "\n",
        "# Setting mask_selection_length will trim or pad the mask outputs to shape\n",
        "# (batch_size, PREDICTIONS_PER_SEQ).\n",
        "masker = keras_nlp.layers.MaskedLMMaskGenerator(\n",
        "    vocabulary_size=tokenizer.vocabulary_size(),\n",
        "    mask_selection_rate=MASK_RATE,\n",
        "    mask_selection_length=PREDICTIONS_PER_SEQ,\n",
        "    mask_token_id=tokenizer.token_to_id(\"[MASK]\"),\n",
        ")\n",
        "\n",
        "# Write a function that preprocess the data and returns features, labels, weights\n",
        "def preprocess(inputs) -> Tuple[Dict[str, tf.Tensor], tf.Tensor, tf.Tensor]:\n",
        "    features = {\n",
        "        \"token_ids\": ...,\n",
        "        \"mask_positions\": ...\n",
        "    }\n",
        "    return None\n",
        "\n",
        "# We use prefetch() to pre-compute preprocessed batches on the fly on the CPU.\n",
        "pretrain_ds = wiki_train_ds.map(\n",
        "    preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",
        ").prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "pretrain_val_ds = wiki_val_ds.map(\n",
        "    preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",
        ").prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Preview a single input example.\n",
        "print(pretrain_val_ds.take(1).get_single_element())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1BigSQ6rgYV"
      },
      "source": [
        "# Encoder Only Transformer\n",
        "\n",
        "We will be creating an encoder only block so that we only deal with self-attention. Create an encoder block using the following parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ws3_Upeq9Ic"
      },
      "outputs": [],
      "source": [
        "# Model params.\n",
        "NUM_LAYERS = 3\n",
        "MODEL_DIM = 256\n",
        "INTERMEDIATE_DIM = 512\n",
        "NUM_HEADS = 4\n",
        "DROPOUT = 0.1\n",
        "NORM_EPSILON = 1e-5\n",
        "\n",
        "# What do each of these parameters represent?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "UxicJxG5qodk",
        "outputId": "0826c564-af4b-4ea6-adfd-7fc570ad71df"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ token_and_position_embedding    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,846,400</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)     │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ layer_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ transformer_encoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │    <span style=\"color: #00af00; text-decoration-color: #00af00\">527,104</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │    <span style=\"color: #00af00; text-decoration-color: #00af00\">527,104</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ transformer_encoder_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │    <span style=\"color: #00af00; text-decoration-color: #00af00\">527,104</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                           │            │\n",
              "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ token_and_position_embedding    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │  \u001b[38;5;34m7,846,400\u001b[0m │\n",
              "│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)     │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ layer_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │        \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │          \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ transformer_encoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │    \u001b[38;5;34m527,104\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │    \u001b[38;5;34m527,104\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ transformer_encoder_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │    \u001b[38;5;34m527,104\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                           │            │\n",
              "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,428,224</span> (35.97 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,428,224\u001b[0m (35.97 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,428,224</span> (35.97 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,428,224\u001b[0m (35.97 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "encoder_model = keras.Model(inputs, outputs)\n",
        "encoder_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3A9vwM7sMkV"
      },
      "source": [
        "Since this is a Masked Language Modelling Task, we will need to attach a Masked Model Head:\n",
        "\n",
        "![masked_model](https://editor.analyticsvidhya.com/uploads/22971fig-3.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJSsDlZ1vvFE"
      },
      "outputs": [],
      "source": [
        "# Training params.\n",
        "PRETRAINING_LEARNING_RATE = 5e-4\n",
        "PRETRAINING_EPOCHS = 8\n",
        "FINETUNING_LEARNING_RATE = 5e-5\n",
        "FINETUNING_EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKiQUXliq8fc"
      },
      "outputs": [],
      "source": [
        "# Create the pretraining model by attaching a masked language model head.\n",
        "inputs = {\n",
        "    \"token_ids\": keras.Input(shape=(SEQ_LENGTH,), dtype=tf.int32, name=\"token_ids\"),\n",
        "    \"mask_positions\": keras.Input(\n",
        "        shape=(PREDICTIONS_PER_SEQ,), dtype=tf.int32, name=\"mask_positions\"\n",
        "    ),\n",
        "}\n",
        "\n",
        "\n",
        "# Define and compile our pretraining model.\n",
        "pretraining_model = keras.Model(inputs, outputs)\n",
        "\n",
        "#Compile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNExzokgv5Y5",
        "outputId": "5ec9be4a-e877-4f65-8749-b99268223a6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m5857/5857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m994s\u001b[0m 165ms/step - loss: 5.4042 - sparse_categorical_accuracy: 0.1437 - val_loss: 3.4693 - val_sparse_categorical_accuracy: 0.3540\n",
            "Epoch 2/8\n",
            "\u001b[1m2220/5857\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m9:44\u001b[0m 161ms/step - loss: 3.6629 - sparse_categorical_accuracy: 0.3321"
          ]
        }
      ],
      "source": [
        "# Pretrain the model on our wiki text dataset.\n",
        "pretraining_model.fit(\n",
        "    pretrain_ds,\n",
        "    validation_data=pretrain_val_ds,\n",
        "    epochs=PRETRAINING_EPOCHS,\n",
        ")\n",
        "\n",
        "pretraining_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Classification (e.g., Sentiment Analysis):**\n",
        "\n",
        "+ **Fine-tuning**: The final hidden state corresponding to the [CLS] token (often the first token in the sequence) is taken as the aggregate representation of the input sequence. This representation is passed through a dense layer to produce a prediction for the classification task.\n",
        "+ **Inference**: For a new input text, it's tokenized and passed through BERT. The output corresponding to the [CLS] token is processed by the dense layer, yielding a class label.\n",
        "\n",
        "**Question Answering (e.g., SQuAD)**:\n",
        "\n",
        "+ **Fine-tuning**: For each token in the input, the model predicts two scores - one for being the start of the answer span and one for being the end of the answer span.\n",
        "+ **Inference**: For a new question and context pair, the model identifies the span in the context with the highest combined start and end scores as the predicted answer.\n",
        "\n",
        "**Named Entity Recognition (NER)**:\n",
        "\n",
        "+ **Fine-tuning**: Each token in the sequence is associated with a label (e.g., person, organization, etc. or O for 'no entity'). The hidden state of each token is processed by a dense layer to predict the label.\n",
        "+ **Inference**: For a new input text, each token's output is processed to predict its entity label.\n",
        "\n",
        "**Text Similarity or Pairwise Tasks**:\n",
        "\n",
        "+ **Fine-tuning**: Similar to text classification, the [CLS] token representation can be used to predict a similarity score or class label for a pair of sentences.\n",
        "+ **Inference**: For a new pair of texts, the combined representation (often based on the [CLS] token) is used to predict their relationship.\n",
        "In all cases, the process is generally as follows:"
      ],
      "metadata": {
        "id": "CJf0nA9kqRqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Masking\n",
        "\n",
        "Training the language model in BERT is done by predicting 15% of the tokens in the input, that were randomly picked. These tokens are pre-processed as follows — 80% are replaced with a “[MASK]” token, 10% with a random word, and 10% use the original word. The intuition that led the authors to pick this approach is as follows (Thanks to Jacob Devlin from Google for the insight):\n",
        "\n",
        "If we used [MASK] 100% of the time the model wouldn’t necessarily produce good token representations for non-masked words. The non-masked tokens were still used for context, but the model was optimized for predicting masked words.\n",
        "\n",
        "If we used [MASK] 90% of the time and random words 10% of the time, this would teach the model that the observed word is never correct.\n",
        "\n",
        "If we used [MASK] 90% of the time and kept the same word 10% of the time, then the model could just trivially copy the non-contextual embedding.\n",
        "\n",
        "No ablation was done on the ratios of this approach, and it may have worked better with different ratios. In addition, the model performance wasn’t tested with simply masking 100% of the selected tokens"
      ],
      "metadata": {
        "id": "2g4l-D9rPLu7"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHhij/J+LMM7Q9JU2os2pX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}